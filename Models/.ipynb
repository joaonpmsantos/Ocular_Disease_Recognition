{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"~/code/joaonpmsantos/Ocular_Disease_Recognition/Data_Analysis/df_binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target_D'] = (data['labels'] != \"['D']\").astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"code/joaonpmsantos/Ocular_Disease_Recognition/raw_data/preprocessed_images\"\n",
    "imgs = []\n",
    "images_path = [elt for elt in os.listdir(os.path.join(Path.home(),data_path)) if elt.find('.jpg')>0]\n",
    "for file in data.filename[:1000]:\n",
    "    path = os.path.join(Path.home(),data_path, file)\n",
    "    if os.path.exists(path):\n",
    "        image = Image.open(path)\n",
    "        imgs.append(np.array(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 512, 512, 3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(imgs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(imgs), data.target_D[:1000], train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_own_model():\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Rescaling(1/255, input_shape = (512,512,3)))\n",
    "  model.add(layers.Conv2D(64, (5,5), activation=\"relu\", padding=\"same\", strides=(1,1)))\n",
    "  model.add(layers.Conv2D(64, (4,4), activation=\"relu\", padding=\"same\", strides=(1,1)))\n",
    "  model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "  model.add(layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\", strides=(1,1)))\n",
    "  model.add(layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\", strides=(2,2)))\n",
    "  model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "  model.add(layers.Conv2D(512, (3,3), activation=\"relu\", padding=\"same\", strides=(1,1)))\n",
    "  model.add(layers.Conv2D(512, (3,3), activation=\"relu\", padding=\"same\", strides=(1,1)))\n",
    "  model.add(layers.Conv2D(512, (2,2), activation=\"relu\", padding=\"same\", strides=(2,2)))\n",
    "  model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "  model.add(layers.Conv2D(512, (2,2), activation=\"relu\", padding=\"same\", strides=(1,1)))\n",
    "  model.add(layers.Conv2D(512, (2,2), activation=\"relu\", padding=\"same\", strides=(1,1)))\n",
    "  model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "  \n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(512, activation=\"relu\"))\n",
    "  model.add(layers.Dense(126, activation=\"relu\"))\n",
    "  model.add(layers.Dense(64, activation=\"relu\"))\n",
    "  model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "  \n",
    "  model.compile(optimizer=\"adam\",\n",
    "                loss=\"binary_crossentropy\",\n",
    "                metrics=[\"accuracy\",\"Recall\"])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24285714285714285"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(y_train == 0)[0])/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',classes=np.unique(y_train), y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.05882353, 0.66037736])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center = False,\n",
    "    featurewise_std_normalization = False,\n",
    "    rotation_range = 10,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    horizontal_flip = True,\n",
    "    zoom_range = (0.8, 1.2),\n",
    "    ) \n",
    "\n",
    "datagen.fit(X_train[np.where(y_train == 0)[0]])\n",
    "datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =load_own_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "16/16 [==============================] - 494s 31s/step - loss: 0.6807 - accuracy: 0.3313 - recall: 0.2143 - val_loss: 0.6898 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 2/70\n",
      "16/16 [==============================] - 505s 32s/step - loss: 0.6777 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6812 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 3/70\n",
      "16/16 [==============================] - 540s 34s/step - loss: 0.6777 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6773 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 4/70\n",
      "16/16 [==============================] - 511s 32s/step - loss: 0.6770 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6829 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 5/70\n",
      "16/16 [==============================] - 534s 34s/step - loss: 0.6772 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 6/70\n",
      "16/16 [==============================] - 570s 36s/step - loss: 0.6772 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6815 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 7/70\n",
      "16/16 [==============================] - 558s 35s/step - loss: 0.6770 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6780 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 8/70\n",
      "16/16 [==============================] - 3678s 243s/step - loss: 0.6773 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6751 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 9/70\n",
      "16/16 [==============================] - 1039s 65s/step - loss: 0.6770 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6773 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 10/70\n",
      "16/16 [==============================] - 1032s 65s/step - loss: 0.6769 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6765 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 11/70\n",
      "16/16 [==============================] - 1033s 65s/step - loss: 0.6770 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6767 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 12/70\n",
      "16/16 [==============================] - 683s 41s/step - loss: 0.6772 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6771 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 13/70\n",
      "16/16 [==============================] - 536s 33s/step - loss: 0.6770 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6745 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 14/70\n",
      "16/16 [==============================] - 532s 33s/step - loss: 0.6772 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6690 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 15/70\n",
      "16/16 [==============================] - 533s 33s/step - loss: 0.6773 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6780 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 16/70\n",
      "16/16 [==============================] - 530s 33s/step - loss: 0.6769 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6769 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 17/70\n",
      "16/16 [==============================] - 523s 33s/step - loss: 0.6769 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 18/70\n",
      "16/16 [==============================] - 529s 33s/step - loss: 0.6769 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6747 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 19/70\n",
      "16/16 [==============================] - 524s 33s/step - loss: 0.6771 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6766 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 20/70\n",
      "16/16 [==============================] - 540s 34s/step - loss: 0.6769 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6763 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 21/70\n",
      "16/16 [==============================] - 532s 33s/step - loss: 0.6770 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6788 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 22/70\n",
      "16/16 [==============================] - 514s 32s/step - loss: 0.6771 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6773 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 23/70\n",
      "16/16 [==============================] - 511s 32s/step - loss: 0.6769 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.7204 - val_recall: 1.0000\n",
      "Epoch 24/70\n",
      "16/16 [==============================] - 521s 33s/step - loss: 0.6770 - accuracy: 0.7730 - recall: 1.0000 - val_loss: 0.6778 - val_accuracy: 0.7204 - val_recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x175520a60>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=70, \n",
    "          batch_size=32, validation_split=0.3, callbacks=[EarlyStopping(patience=10, restore_best_weights=True)], \n",
    "          class_weight={0:class_weights[0],1:class_weights[1]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
